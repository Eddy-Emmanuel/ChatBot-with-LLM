{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63989530-99e8-4316-b60b-2318820c669d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from warnings import filterwarnings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "filterwarnings(action=\"ignore\")\n",
    "\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import trim_messages, HumanMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableWithMessageHistory, RunnablePassthrough\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05031f37-2603-4ef2-ac0f-63a868c613f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2fbca0-37f2-498c-a148-e8cdc96a5b13",
   "metadata": {},
   "source": [
    "#### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa204efa-8d0e-4a6c-ad5b-d7b46a649483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000018002A158B0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018002A16390>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_model = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "groq_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68cc2a-64f1-45fc-a191-5359aed4210f",
   "metadata": {},
   "source": [
    "#### Adding Prompt to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4a0a20-e230-4d22-88cf-1db7abeba1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['user_input'], input_types={'user_input': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000018000C17C40>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You're a helpful Q/A conversational bot. Answer each questions to the best of your capability.\"), additional_kwargs={}), MessagesPlaceholder(variable_name='user_input')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prompt = ChatPromptTemplate(messages=[\n",
    "    (\"system\", \"You're a helpful Q/A conversational bot. Answer each questions to the best of your capability.\"),\n",
    "    MessagesPlaceholder(variable_name=\"user_input\"),\n",
    "    # (\"user\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "model_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f611950-045c-484d-b837-98c46b73b77c",
   "metadata": {},
   "source": [
    "#### Adding Conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d669fbc8-8a32-4995-ae86-2708fae4fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BotMemory:\n",
    "    def __init__(self):\n",
    "        self.history = defaultdict(ChatMessageHistory)\n",
    "\n",
    "    def GetMessageHistory(self, chat_id:str)->ChatMessageHistory:\n",
    "        \"\"\"\n",
    "        This helps to retrieve or initialize a session's chat message history.\n",
    "        \"\"\"\n",
    "        return self.history[chat_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6f7b717-16bf-4238-b972-81ef6d1b7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_memory = BotMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b77987-8af4-479d-94c6-5b3d1f5cd350",
   "metadata": {},
   "source": [
    "#### Managing Chat Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d9d1460-1719-4760-ba62-5d864e016e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableLambda(...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_trimmer = trim_messages(max_tokens=128000,\n",
    "                                strategy=\"last\",\n",
    "                                token_counter=groq_model,\n",
    "                                start_on=\"human\",\n",
    "                                include_system=True,\n",
    "                                allow_partial=False,)\n",
    "\n",
    "message_trimmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc70af-d8b6-4624-8d10-f89e16de9d66",
   "metadata": {},
   "source": [
    "#### Creating a Langchain Expression Language i.e chain for the prompt and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "334d7b39-2bb6-4d3a-a1d7-d7b3314a59bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnablePassthrough()\n",
       "| ChatPromptTemplate(input_variables=['user_input'], input_types={'user_input': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000018000C17C40>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You're a helpful Q/A conversational bot. Answer each questions to the best of your capability.\"), additional_kwargs={}), MessagesPlaceholder(variable_name='user_input')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000018002A158B0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018002A16390>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_chain = (RunnablePassthrough(messages=itemgetter(\"messages\")|message_trimmer) \n",
    "               | model_prompt \n",
    "               | groq_model)\n",
    "\n",
    "model_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e431e3-f7d7-47ca-b952-a02243098cde",
   "metadata": {},
   "source": [
    "#### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99139f38-20ce-4872-bfb7-8c45495c64de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<bound method BotMemory.GetMessageHistory of <__main__.BotMemory object at 0x000001807FEABB90>>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_with_memory = RunnableWithMessageHistory(model_chain, bot_memory.GetMessageHistory)\n",
    "\n",
    "bot_with_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30eb4c-09d3-46b0-bba1-b5e5e414d073",
   "metadata": {},
   "source": [
    "#### Run Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4fbf6c9-64e9-4382-adcb-532aee13e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     user_input = input(\"User:\")\n",
    "#     if user_input != \"end\":                \n",
    "#         bot_response = bot_with_memory.invoke(\n",
    "#                                               {\"user_input\": [HumanMessage(content=user_input)]}, \n",
    "#                                               config={\"configurable\": {\"session_id\": \"Eddy\"}}\n",
    "#                                               ).content\n",
    "#         print(f\"Bot: {bot_response}\", end=\"\\n\\n\")\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cc3e2-3527-4311-99d1-b921877f2ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP_ENV]",
   "language": "python",
   "name": "conda-env-NLP_ENV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
